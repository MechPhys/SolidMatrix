# SolidMatrix: Solid particles in a matrix

> "Nature is, above all else, a meticulous accountant"

Previously, I tried to implement a coherent computational model of quantum physics based purely on wave equations, which I called Wave ELectroDynamics [WELD](https://github.com/MechPhys/weld).  The result was a coupled system of Dirac and Maxwell equations for an electron in an EM field, implemented using local laplacian update equations in a cubic 3D lattice.  The main problem was that the pure wave model just ended up oozing all over the place, and it was very difficult to reconcile the result with any kind of conservation of charge, particle number, or anything really.

SolidMatrix is a new approach that is based on "solid" point-like particles occupying cells in a discrete lattice (matrix).  These discrete particles are much better for keeping the accounting in order (i.e., strict conservation of energy, charge, particle numbers, etc): a particle occupies a cell fully, and then moves (fully) to a new location, perfectly preserving all of its state.  But how does such a discretized particle move in a seemingly continuous fashion in arbitrary directions, without significant "aliasing" effects from the underlying cubic lattice?  This was nicely solved by the wave equations, which even when implemented in a discrete lattice exhibited very good symmetry of propagation, by using all 26 neighbors.

One key insight motivating this new approach is that _stochastic motion_, where there is a certain probability of taking a step at each point in time, provides a way of smoothing the motion of these discrete particles.  Critically, this stochastic motion provides a necessary origin story for the randomness at the heart of quantum physics.  Furthermore, the connection between stochastic (brownian) motion and QM wave equations was developed by Nelson (1966) building on original ideas from Feynmann (see Sciarretta, 2018 for a historical overview).

A central intuition is that slow drift produces a wide cloud of space where particle could be, corresponding to a long wavelength in the probability cloud that the Schrodinger wave function describes.  However, when the particle has high momentum, it moves more deterministically in a given direction, resulting in a narrower range of variance around the particle's mean trajectory, resulting in a narrower effective wavelength.

More generally, the discrete framework does a great job of keeping the accounting tight.  The discrete localization of particles to one cell of a matrix allows for a complete energy-conserving accounting of particle interactions, in a way that eludes any distributed particle system, where it is very difficult and non-local to "gather all the far-flung bits of a particle" and alter them in some systematic way necessary to conserve energy during an interaction.

The resulting physical model is similar to the de Broglie-Bohm _pilot wave_ theory: the discrete particles interact with a sea of surrounding fields that impart the wave-like properties of QM, and their random motion steps are guided by the wave field.  The surrounding wave field is essential for the particle to be able to properly "sense" the force field effects from electromagnetic (EM) and other forces (weak, strong).  Thus, the wave field functions like an _antenna_ or "whiskers" in sensing forces over a broader space, beyond its own singular cell.

Unlike fermion particles such as electrons, the EM field is not amenable to a discrete particle-like framework: "photons" have many problematic issues as discrete particles of the EM field, as elaborated below.  Therefore, it makes more sense to retain a "classical" EM field, interacting with the discretized fermion cells, as in the _semiclassical_ approach developed by a number of researchers (see [Struyve, 2020; Santos, 2015](#references)).  

Thus, a hybrid particle-wave framework solves "practical" issues by enabling discrete particles to interact with each other at a distance through force fields, and thus provides a compelling "origin story" for the otherwise puzzling wave-particle duality at the heart of quantum physics.

More generally, the current approach is motivated by attempting to find a computationally coherent, practically implementable algorithm for generating the phenomena of quantum physics, with an eye toward cases where the strong constraints imposed by this approach coincide with the seemingly inexplicable phenomenology of quantum physics.  If these strange and counter-intuitive properties of known physics can be understood as necessary requirements to implement key qualitative properties of physics (e.g., strong conservation laws _and_ long-range force-field interactions among particles), then we can perhaps derive a deeper understanding of the fundamental laws of nature, which then become more _necessary_ than _arbitrary_ and _paradoxical_.

The current effort was initially inspired by the recent work of [Antonio Sciarretta](#references), who has developed models based on similar principles, showing how a particular formulation of the surrounding field interactions can give rise to otherwise puzzling features of quantum physics.  In particular, these field interactions introduce a novel framework for understanding interference effects, in terms of the cumulative _traces_ left by other particles.  This twist may well provide a critical missing ingredient that finally makes the quantum world make sense: it is well-established that quantum effects manifest only over many repeated samples from "identically prepared" particles, and yet everyone interprets them in terms of physical mechanisms operating "instantaneously" on every single trial.  This fundamental disconnect has great potential for resolving paradoxes.

This approach also converges with the research on the zero-point field, as developed by Santos, Marshall and others, which attempts to explain the nature of _virtual particles_ captured in the path-integral formulation of Feynmann and his famous diagrams.  The field is very much "alive", teaming with random "quantum foam", and this fabric of "empty" space likely plays an essential role in explaining various puzzling features of QM.  In the stochastic electrodynamics (SED) approach, the field is the exclusive source of stochastic behavior.  However, the isotrophic motion of discrete particles requires intrinsic stochasticity, thus freeing the field to play a less strongly-constrained role.

In short, we have several different models of the quantum field: the original S field formulation from Bohm, the path integral of Feynmann (which is divergent in general), the second quantized Fourier space formulation of quantum field theory, the SED / ZPF field, and Sciarretta's specific "trace" field.  Between all of these models, some kind of consistent framework should be derivable.

## Virtual particles, the discrete lattice, and probability waves

Virtual particles are an essential feature of QED / quantum field theory, and yet their "ontological" status is clearly somewhat confusing: they aren't the "real" particles that we observe, and yet their fleeting existence is necessary for the theory to work, so in some sense they must be just as real as the "real" particles.

The discrete particle lattice framework provides a potential resolution to this conundrum.  If any given "real" particle can potentially occupy any given cell in a discrete lattice, then there must effectively be a "slot" reserved for such a particle in each cell.  These empty slots could provide an appealing basis for virtual particles, and the propagation and interactions of particles in the matrix.

In particular, a simple schema is that the probability waves associated with the standard interpretation of QM reflect a rippling propagation of probability factors across virtual particle slots in the matrix, with a real particle having a special status as being the current "true" location.  Each possible jump to a neighboring cell involves a full transition matrix dependent upon the total energy (mass + kinetic) of the source: if the source is sufficiently energetic, it has some probability of activating a different combination of real particles as it makes the leap, accounting for the splitting tracks observed in particle accelerator experiments.  Perhaps some of the "trace" in the matrix represents residual bits of this probability field propagating out and being left behind as real particles move around.

It is essential that these probability computations are all propagated in terms of _amplitudes_, not the probability values themselves, which are obtained by the product with the complex conjugate ("squaring").

## The static programmability constraint

The overall goal of this approach can be summarized in terms of the properties of a computer program that implements it [(O'Reilly, 2011)](#references).  The best case scenario is that all the seemingly arbitrary and puzzling aspects of quantum physics fall out naturally from this perspective, providing a unifying overall framework for _how_ Nature could actually run physics in a fully autonomous, self-contained manner.  By contrast, existing physics frameworks require case-specific and incomplete mathematical approaches, and only generate approximate solutions to particular physical situations.

In particular, an autonomous implementation of physics must:

* Use a comprehensive "static" state representation that can contain all the relevant degrees of freedom, _without requiring dynamic memory allocation_ at random points.  We can't really have Nature dipping into some kind of central memory allocation pool and dishing out bits of relevant state here and there as needed.  Everything needs to have its place, and physics is just the updating of this state matrix.

* Interactions are fully local (nearest neighbor on the grid), as in a cellular automaton, because again the alternative would require arbitrary subroutines of processing to be performed in different locations at different points in time: how would all this get coordinated and allocated?  Autonomous physics means _no daemons_ -- everything "just runs" automatically, following the same rules over and over again.

In this framing, the goal is to come up with the probability-amplitude based equations for how each particle state moves through the matrix over time.  If this can be done for low-energy electrons in the EM field, as a starting point, then presumably it could be generalized to more types of particles etc.  The heavier muon and tau leptons, and the corresponding neutrinos, are potentially all reducible to one underlying particle type, which is variously "decorated" or parameterized with respect to mass and charge, and their interactions with the weak force.  Neutrinos seem particularly important as pervasive inhabitants of the background matrix that could be responsible for some aspects of the "trace" and randomness phenomena.  Working through all of that, along with the basis for spin, would be a logical next step.

## Measurement and wavefunction collapse

The specific example of the Born rule and the mysterious collapse of the wave function at the point of _measurement_, which remains one of the most important unsolved conceptual problems at the heart of quantum physics, is particularly illustrative for the defining features of this approach.

Under the classical Copenhagen interpretation, Schroedinger etc wave functions define the evolution of a _probability field_ for where a particle might be found at some point in time.  But at some imprecisely-defined moment of "measurement", this probability field collapses down to a single definite point, where the particle was actually observed.  But how could this spatially distributed field, which could spread out without bound and in principle cover the entire universe, _instantaneously collapse_ to a single point?  It just makes no physical sense, even while it makes practical mathematical sense in terms of predicting outcomes of experiments.

From a programming perspective, this instantaneous collapse is completely untenable.  Imagine the `for` loop that would be necessary to track down all the far-flung bits of the probability field, and the challenges of dealing with very tiny values (is there a cutoff?) -- it would require a massive computational load for something that is presumably happening everywhere, all the time, in parallel throughout the universe.

The obvious alternative is that the probability wave describes the behavior of a local, presumably stochastic process, _where the particle remains definitively localized at all times_.  This framework avoids any need for wave function collapse, and could be directly implemented in a computer simulation.  The deBroglie-Bohm _pilot wave_ framework advanced this idea, where a particle is guided in its trajectory by some kind of wave function, but retains a definite location at all times.

## QM Probability functions conflate epistemic and aleatoric uncertainty

Critically, the classical QM probability function formulation conflates _epistemic_ (derived from an observers lack of knowledge) and _aleatoric_ (true, irreducible) uncertainty: the "unobserved" particle inexorably increases the spread of its wave function in proportion to the amount of time it remains unobserved, for purely epistemic reasons having to do with "losing track" of where the particle has gone off to.  However, the "true" uncertainty in its position under an "ideal observer" scenario may remain relatively precise.  Recent experiments have shown that, contrary to Copenhagen dogma, it is indeed possible to infer a lot about the properties of a particle without performing a full-fledged measurement, i.e., _weak measurements_.  This implies that a potentially significant portion of quantum uncertainty is epistemic in nature.  In general, this data has been taken as support of the de Broglie-Bohm framework, where there are "real" underlying properties of particles.

This distinction between epistemic and aleatoric uncertainty highlights the critical difficulty in distinguishing the calculational tools that are useful at a practical level for computing the results of experiments (given our general lack of epistemic access to the underlying states of the world), versus the actual _laws of nature_ that apply "under the hood" in updating the physical state of the universe from one moment to the next [(O'Reilly, 2011; Santos, 2015)](#references).

## Entanglement

A key example of the challenge in distinguishing calculational tools from "real physics" arises in attempting to explain the non-local _entanglement_ phenomena in QM from within the de Broglie-Bohm pilot wave framework.   Quantum entanglement occurs whenever the aggregate quantum state of a system is not a simple product of its constituents: i.e., there is some kind of interdependency between the elements.  A prototypical case arises due to a conservation law, e.g., a zero spin particle forming two 1/2 spin particles, which must therefore have opposite spins.

In the Copenhagen interpretation, the final wave function collapse at the time of measurement reveals the interdependencies among these parts, even if they have become widely separated in space.  J.S. Bell has famously shown that the now well-established empirical results demonstrating these entanglement effects are incompatible with certain broad classes of physical models based on local realism, where "hidden variables" carried by the two particles somehow explain the complementary nature of the resulting measurements.

As with all such wave function collapse events, the entanglement case appears to require a completely non-local, instantaneous "physical" interaction across potentially far-flung reaches of space.  Although people have gone to great pains to try to argue that this instantaneous wave collapse somehow does not violate the strong locality constraints implied by relativity (e.g., via a "no signaling" proof), it is clear that such arguments are far from convincing [(e.g., Durr et al., 2014)](#references).

In the deBroglie-Bohm framework, which maintains local variables for each particle, accounting for the phenomenon of entanglement (and any other truly quantum-mechanical interaction phenomenon) requires that the wave function be defined in a _configuration space_ that is 3N dimensional, where N is the number of interacting particles.  Because there is no obvious limit to the number of such particles, in principle the entire Universe must enter into this huge configuration-space wave function, which would be beyond impossible for any finite computational device to implement.  Bohm and Hiley refer to this as the "undivided universe".

It remains unclear, however, whether such an implausibly large wave function formulation is actually a _necessary_ aspect of the pilot-wave framework, or whether it is just a byproduct of using conventional QM approaches for analyzing multi-particle interactions [(Norsen et al., 2015)](#references).  In particular, standard QM defines a wave function for the _entire system_ using the same kinds of underlying operators that otherwise were developed based on individual free particles.  This implies certain assumptions about the nature of the interactions among such particles (and builds in all the confounds about epistemic vs. aleatoric uncertainty).  While it may work out at a mathematical level when making these assumptions, there is no obvious reason why the actual underlying physical dynamics of the system need to obey these assumptions.

Specifically, [Norsen et al. (2015)](#references) show that good approximations to standard QM behavior can be obtained using _separate_ wave functions for each interacting particle, plus a simple additional potential field function that accounts for the interactions.  That paper, and [Norsen, 2017](#references), also provide an incredibly clear and compelling account of the overall physical interpretability of quantum physics frameworks (and likewise contrast physical models with calculational tools), and present a strong case for the promise of something along the lines of the current endeavor, based on the pilot-wave framework.  Furthermore, it is possible to derive relativistic versions of the pilot-wave model that do _not_ violate non-locality, but it remains difficult to determine if such systems produce the same predictions as the standard abstract QM calculational models [Durr et al. (2014)](#references).

Thus, it is possible that a pilot-wave system using relativistic wave equations and laws of motion could reproduce observed data, as an _emergent_ phenomenon of the complex interactions among the evolving states driven by entangled particles as they move away from each other and interact with other elements of an apparatus.  Whereas even very simple forms of interaction among particles goes a long ways toward capturing actual QM behavior [(Norsen et al.,  2015)](#references), the more complex dynamics of particles interacting through wave and force fields could plausibly generate the kinds of non-linear interactions that the configuration space formalism otherwise captures in summary form.

Thus, the critical refrain here is that there are all manner of simple _mathematical models_ in physics that are almost certainly not viable _physical models_ for how physics actually unfolds autonomously over time.  Here, we seek the small (unique?) subset of models that makes good physical sense in terms of the above programmability constraints, and yet are capable of accurately generating known physics.

## Spin-statistics and Pauli Exclusion

The [Pauli exclusion principle](https://en.wikipedia.org/wiki/Pauli_exclusion_principle) holds that, for _fermions_ (electrons, quarks etc, with a quantum spin of 1/2), only one particle can occupy a given quantum state at a time.  This exclusion is consistent with a solid matrix state representation with only one slot of a given spin per cell (two fermions with opposite spins can occupy the same position).  According to standard QM, this exclusion applies at the level of particle identity, including the _generation_ difference (e.g., electron vs. muon) [see physics forums answer](https://www.physicsforums.com/threads/pauli-exclusion-across-the-three-generations.586042/), so the number of "slots" in the matrix is equivalent to the number of elementary particles times 2 (for each spin).

Overall, this basic physical property of exclusion aligning so conveniently with a discrete matrix state representation is a boost for the explanatory power of the framework.

## Bosons are not discrete

However, the tricky part comes with _bosons_ (e.g., photons, spin 1), which do _not_ obey any exclusion principle, and thus appear to require some entirely different form of representation in our matrix state.  Photons are the carriers of the EM force, and it remains unclear how one could conceptualize the particle-like nature of this force within the current framework.

For example, the energy of a photon is proportional to its frequency, which is a continuously-varying quantity, so how could a discrete particle-like state represent the number of such particles at each frequency?  You would need infinitely many bins, each of which holding an indeterminant number of particles, each of which has other properties such as a direction or polarization vector.  By contrast, all the fermion properties except momentum are discrete per particle (charge, spin, rest mass).

Furthermore, to exert the EM force, a particle must be constantly emitting photons at all times: how can one ensure that these photons uniformly fill the space if they are discrete particles following discrete trajectories?  In addition, the magnetic and electric potentials are well-defined in terms of vector field properties, and it is unclear how these could be sufficiently implemented via discrete particles.  Furthermore, the smoothness of stochastic brownian motion only works for sub-light-speed propagation: a particle moving at light speed (corresponding to moving one lattice cell per unit time) has no such options.

In short, it just makes much more sense to conceptualize the EM force in terms of the standard Maxwell equations, instead of in terms of discrete photon particles.  Many authors have pointed out these and other problems with the photon model, as reviewed in [(O'Reilly, 2011)](#references), and the semiclassical approach has had good success in accounting for the phenomena that have otherwise been attributed to photons (see [Santos, 2015](#references)).  In short, the particle-like phenomena can all be attributed to the particle-based properties of the _fermions_ interacting with the EM field, instead of requiring discrete photons.

In the specific approach taken here, it is the distributed wave field surrounding a fermion particle that interacts with the EM wave field, and thus steers the probabilistic trajectory of the particle, even as that particle is also driving the quantum and EM wave fields surrounding it.  Properly capturing this complex interaction is a primary goal of the computational modeling approach taken here.

Finally, it is important to also appreciate that while composite particles made of fermions can behave like bosons, e.g., in the Bose-Einstein Condensate, this does not violate the exclusion principle for the underlying fermions: these composite molecules are _not_ occupying the same physical space -- they are just sharing some kind of higher-order quantum state that leads to extreme coherence, or something like that.

# Summary and proposed approach

The current approach is unapologetically _classical_ in emphasizing "actual physics" over mathematical abstractions, in attempting to align the major _phenomenological_ properties of quantum physics with a physical ontology that could plausibly be implemented as a computational model with local dynamics that are strictly compatible with relativistic constraints (nothing propagates faster than the speed of light).  The major such alignments between phenomenology and underlying mechanisms are:

* **Wave-particle duality:**  This is perhaps the most confusing, paradoxical, and yet central feature of quantum physics.  We argue that it is necessary to satisfy the dual requirements of: a) strict conservation laws that prevent the overall system from blowing up or dwindling away over time, and b) force-fields that enable particles to interact with each other over very long distances relative to particle sizes (e.g., in terms of Compton wavelength scales).  Force fields are great for continuously filling space with a signal eminating from a charged particle, spreading out in a 1/r^2 manner uniformly throughout space at the speed of light.  It is very difficult to imagine how discrete photon particles could accomplish the same feat.  But it is also very difficult to see how a point-like particle could meaningfully interact with a distributed EM force field: the quantum field for fermion particles thus serves as a kind of antenna for capturing those forces and conveying them to influence the motion of the discrete particle.

* **Pauli-exclusion and strict conservation:** The discrete fermion particles have well-defined charge, mass and spin properties, which are all strictly conserved, and there can only be one in a given spatial location.   This is all compatible with a discrete state representation with reserved spaces for each such particle.

* **Virtual particles and path-integral loops:**  It is possible that the very real effects of virtual particles could be captured by partial activations of empty particle slots, under the influence of a real particle's wave function.  Indeed, perhaps the quantum wave function for a fermion, which must be a "real" thing according to the pilot-wave framework, is actually manifest as this partial activation pattern across neighboring lattice cells, thereby naturally computing all the loops that are otherwise captured in the path integral formulation.  Furthermore, this framework naturally explains the fluid nature of particle transformations at higher energies, in terms of probabilities of transitioning to a different configuration of particles at the next step.

* **Special relativity in wave function:**  In the [WELD](https://github.com/MechPhys/weld) model of coupled Dirac - Maxwell equations, it was clear how the time and space distortion effects of special relativity emerged from the basic properties of the matter wave function.  By pursuing a relativistic version of pilot-wave equations based this WELD framework, we hopefully obtain a principled explanation for these relativistic effects.  Historically, the pilot-wave approach has had difficulty dealing with relativistic effects, so this could represent an important advance (see also [Struyve, 2020](#references)).

* **Stochastic propagation:** to smooth out the trajectory of a discrete particle on a cubic lattice, inherently stochastic jumps as a function of a continuous overall momentum vector are very useful.  And the brownian nature of this motion itself produces some features captured by the Schrodinger equation.  However, this is not a standard feature of pilot-wave formalisms (which are expressed using continuous-valued positions etc).  How is this aspect of motion related to the overall pilot wave function?

## Outstanding challenges

* Sciarretta's specific formulation has some strange features, including that the interaction depends on the specific lifetime of the particle.  However, in practice the field is initialized to an equilibrium distribution, based on the configuration.  Thus, in the end, the field "senses" the configuration and imparts corresponding forces onto the particle, which is the same qualitative account as the pilot wave framework.  Furthermore, Sciarretta's model has an appealing conserving exchange process in the particle's interaction with the field.

* How exactly does the fermion particle couple to its own field?  Answers should be in various papers, for Dirac case even.

* How do the EM -- Dirac -- particle interactions actually take energy out of the EM field (equivalent to absorbing a photon), and how do they inject energy into it (and where does that energy come from?)

* How do we formulate the Dirac field within the overall fermion state space, and how does this interact with the field for other particles, etc.  How does the particle "generate" its own field, and keep it reasonably localized?  We don't want to mistakenly include epistemic uncertainty into the wave function, so it needs to remain much more localized than is typical, presumably by virtue of constantly being generated by the discrete particle.

* Sciarretta introduced a potentially game-changing notion of particles leaving traces in the underyling lattice state, that then introduce interference effects _over time_ as other particles go down the same paths.  However, given that the Earth and solar system are moving through space, these trace effects also need to keep moving through the lattice in sync with the rest of an Earth-bound apparatus, relative to the privileged reference frame of the lattice itself (which remains undetectable due to the relativistic properties of Dirac waves).  Also, what is the role of blackbody noise and the ever-present sea of neutrinos in driving wave fluctuations and overall randomness?


## One particle stochastic equations of motion

![Stochastic Origin of Quantum Momentum / Frequency Relationship](figs/fig_asmom5_0_autoc.png?raw=true "Stochastic Origin of Quantum Momentum / Frequency Relationship.  The momentum on the left is 0.5c while on the right is 0. The distribution of position is on the vertical axis, while time is on the horizontal axis, with each point centered at the origin in the center (i.e., the temporal autocorrelation function).  The variance on the left is half of that on the right.")

Nelson (1966) shows how brownian stochastic motion gives rise to the Schrodinger equation: a central intuition is that slow drift produces a wide cloud of space where particle could be, corresponding to a long wavelength in the probability cloud that the Schrodinger wave function describes.  However, when the particle has high momentum, it moves more deterministically in the given direction, resulting in a narrower range of variance around the particle's mean trajectory, resulting in a narrower effective wavelength along the direction of motion.  This is illustrated in the above figure.

# References

See https://www.zotero.org/groups/2525742/mechphys/library for an extensive library of relevant papers.

* Dürr, D., Goldstein, S., Norsen, T., Struyve, W., & Zanghì, N. (2014). Can Bohmian mechanics be made relativistic? Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences, 470(2162), 20130699. https://doi.org/10.1098/rspa.2013.0699

* Nelson, E. (1966). Derivation of the Schrodinger Equation from Newtonian Mechanics. Physical Review, 150(4), 1079–1085. https://doi.org/10.1103/PhysRev.150.1079

* Norsen, T., Marian, D., & Oriols, X. (2015). Can the wave function in configuration space be replaced by single-particle wave functions in physical space? Synthese, 192(10), 3125–3151. https://doi.org/10.1007/s11229-014-0577-0

* Norsen, T. (2017). Foundations of Quantum Mechanics: An Exploration of the Physical Meaning of Quantum Theory. https://doi.org/10.1007/978-3-319-65867-4

* Ord GN, Schrödinger's Equation and Classical Brownian Motion, Fortschr. Phys. 46, 6–8, 889–896 (1998).

* O’Reilly, R. C. (2011). Surely You Must All be Joking: An Outsider’s Critique of Quantum Physics. ArXiv:1109.0880]. http://arxiv.org/abs/1109.0880

* Santos E. (2015). Towards a realistic interpretation of quantum mechanics providing a model of the physical world, Foundations of Science 20(4), 357–386. https://doi.org/10.1007/s10699-014-9366-y

* Sciarretta, A. (2018). A Local-Realistic Model of Quantum Mechanics Based on a Discrete Spacetime. Foundations of Physics, 48(1), 60–91. https://doi.org/10.1007/s10701-017-0129-9

* Sciarretta, A. (2018). A Local-Realistic Model of Quantum Mechanics Based on a Discrete Spacetime (Extended version). Foundations of Physics, 48(1), 60–91. http://arxiv.org/abs/1712.03227

* Sciarretta, A. (2021). A local-realistic quantum mechanical model of spin and spin entanglement. International Journal of Quantum Information, 19(01), 2150006. https://doi.org/10.1142/S0219749921500064

* Struyve, W. (2020). Semi-classical approximations based on Bohmian mechanics. International Journal of Modern Physics A. https://doi.org/10.1142/S0217751X20500700

